{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T04:17:55.552704Z",
     "start_time": "2024-11-07T04:17:50.010863Z"
    }
   },
   "source": [
    "from utils import ImageDataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms.v2 import Compose, GaussianBlur, Normalize, RandomHorizontalFlip, RandomResizedCrop, RandomRotation, RandomVerticalFlip, ToDtype, ToImage"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:18:23.056193Z",
     "start_time": "2024-11-07T04:18:23.053320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rng = torch.Generator().manual_seed(77)\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.1\n",
    "WEIGHT_DECAY = 0.001\n",
    "N_EPOCHS = 100\n",
    "IMAGE_DIR = 'Data/downsampled_data'\n",
    "METADATA_PATH = 'Data/metadata_BR00116991.csv'\n",
    "CNN_OUT_PATH = 'cnn.pth'"
   ],
   "id": "73014332ec325b8b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:17:55.583620Z",
     "start_time": "2024-11-07T04:17:55.577331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, output_size: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding='same')\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.mlp1 = nn.Linear(128 * 32 * 32, 256)\n",
    "        self.mlp2 = nn.Linear(256, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.activation = nn.LeakyReLU()        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        x = self.pool(self.activation(self.conv3(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.dropout(self.activation(self.mlp1(x)))\n",
    "        x = self.mlp2(x)\n",
    "        \n",
    "        return x\n"
   ],
   "id": "9a87285b275e44ef",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:18:01.929440Z",
     "start_time": "2024-11-07T04:18:01.923142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_loop(device, classifier, train_loader, optimizer, scheduler, loss_fn, n_epochs):\n",
    "    losses, accs = [], []\n",
    "    classifier.train()\n",
    "    for epoch in range(1, 1+n_epochs):\n",
    "        loss_val = 0\n",
    "        acc_val = 0\n",
    "        n = 0\n",
    "        for (X, y) in tqdm(train_loader):\n",
    "            m = y.size(0)\n",
    "    \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            yhat = classifier(X)\n",
    "            pred = torch.argmax(yhat, dim=1)\n",
    "            \n",
    "            loss = loss_fn(yhat, y)\n",
    "            acc = (pred == y).sum()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_val += loss.item() * m\n",
    "            acc_val += acc.item()\n",
    "            n += m\n",
    "        \n",
    "        print(f'Epoch {epoch}: Loss = {loss_val / n:.3f}; Accuracy = {acc_val / n:.3f}')\n",
    "        losses.append(loss_val / n)\n",
    "        accs.append(acc_val / n)\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return np.array(losses), np.array(accs)\n",
    "        "
   ],
   "id": "ae20587cde7c4693",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:18:07.422819Z",
     "start_time": "2024-11-07T04:18:07.380836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transforms = Compose([\n",
    "    ToImage(),\n",
    "    RandomResizedCrop((256, 256)),\n",
    "    ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "        \n",
    "dataset = ImageDataset(image_dir=IMAGE_DIR, metadata_path=METADATA_PATH, transforms=transforms, convert_rgb=False)\n",
    "train_dataset, test_dataset = random_split(dataset, [0.8, 0.2], generator=rng)\n",
    "train_loader, test_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True), DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "id": "ac8735f0dec40f86",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:26:30.520237Z",
     "start_time": "2024-11-07T04:18:56.904889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('mps')\n",
    "clf = Classifier(dataset.n_classes()).to(device)\n",
    "optim = torch.optim.Adam(clf.parameters(), LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "losses, accs = train_loop(device, clf, train_loader, optim, scheduler, loss_fn, N_EPOCHS)"
   ],
   "id": "6f61081714ebe754",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0acccaaa2fc4baba38b1b238da807e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 123793.530; Accuracy = 0.040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f13e280625294026ad489bc2446a8815"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 44168.996; Accuracy = 0.010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "474cbd5b238241378c440bf44c929873"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mStepLR(optim, step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m      5\u001B[0m loss_fn \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m----> 7\u001B[0m losses, accs \u001B[38;5;241m=\u001B[39m train_loop(device, clf, train_loader, optim, scheduler, loss_fn, N_EPOCHS)\n",
      "Cell \u001B[0;32mIn[5], line 18\u001B[0m, in \u001B[0;36mtrain_loop\u001B[0;34m(device, classifier, train_loader, optimizer, scheduler, loss_fn, n_epochs)\u001B[0m\n\u001B[1;32m     15\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(yhat, y)\n\u001B[1;32m     16\u001B[0m acc \u001B[38;5;241m=\u001B[39m (pred \u001B[38;5;241m==\u001B[39m y)\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m---> 18\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     20\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/stat4243/lib/python3.11/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    523\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    524\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/stat4243/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    267\u001B[0m     tensors,\n\u001B[1;32m    268\u001B[0m     grad_tensors_,\n\u001B[1;32m    269\u001B[0m     retain_graph,\n\u001B[1;32m    270\u001B[0m     create_graph,\n\u001B[1;32m    271\u001B[0m     inputs,\n\u001B[1;32m    272\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    273\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    274\u001B[0m )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:18:49.249086Z",
     "start_time": "2024-11-07T04:18:48.740675Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(clf.state_dict(), CNN_OUT_PATH)",
   "id": "748b5a5aa56e21d8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6730edcd89b4fbeb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
